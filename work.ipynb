{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Data Insights & Aggregated Metrics\n",
    "\n",
    "**Presenter:** Zachary Amadi\n",
    "**Date:** February 25th, 2025\n",
    "\n",
    "This notebook presents an interactive analysis of the DriveWealth Open Library Data Pipeline. The pipeline extracts, transforms, and aggregates book data from the Open Library API (default subject: ‘science_fiction’). Through this interactive exploration, you will be able to view key performance metrics, inspect data quality, and drill down into trends by filtering by author and publication year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Summary\n",
    "\n",
    "- Pipeline Objective: Extract, transform, and aggregate book data for the subject ‘science_fiction’ (modifiable via command-line).\n",
    "\n",
    "- Future Enhancements: Migration to PostgreSQL, distributed processing via Dask, enhanced real-time monitoring.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ipywidgets import interact, Dropdown, SelectMultiple, IntRangeSlider\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading Overview\n",
    "The data for this analysis comes from two CSV files generated by the pipeline: authors.csv (containing author details) and books.csv (containing book details). These files represent the clean, structured outputs of our transformation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authors DataFrame Preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>author_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/authors/OL22098A</td>\n",
       "      <td>Lewis Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/authors/OL25342A</td>\n",
       "      <td>Mary Shelley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/authors/OL23431A</td>\n",
       "      <td>L. Frank Baum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/authors/OL13066A</td>\n",
       "      <td>H. G. Wells</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/authors/OL161167A</td>\n",
       "      <td>Arthur Conan Doyle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            author_id         author_name\n",
       "0   /authors/OL22098A       Lewis Carroll\n",
       "1   /authors/OL25342A        Mary Shelley\n",
       "2   /authors/OL23431A       L. Frank Baum\n",
       "3   /authors/OL13066A         H. G. Wells\n",
       "4  /authors/OL161167A  Arthur Conan Doyle"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books DataFrame Preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>title</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>author_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/works/OL138052W</td>\n",
       "      <td>Alice's Adventures in Wonderland</td>\n",
       "      <td>1865</td>\n",
       "      <td>/authors/OL22098A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/works/OL450063W</td>\n",
       "      <td>Frankenstein or The Modern Prometheus</td>\n",
       "      <td>1818</td>\n",
       "      <td>/authors/OL25342A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/works/OL18417W</td>\n",
       "      <td>The Wonderful Wizard of Oz</td>\n",
       "      <td>1899</td>\n",
       "      <td>/authors/OL23431A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/works/OL52267W</td>\n",
       "      <td>The Time Machine</td>\n",
       "      <td>1895</td>\n",
       "      <td>/authors/OL13066A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/works/OL262460W</td>\n",
       "      <td>The Lost World</td>\n",
       "      <td>1900</td>\n",
       "      <td>/authors/OL161167A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            book_id                                  title  publication_year  \\\n",
       "0  /works/OL138052W       Alice's Adventures in Wonderland              1865   \n",
       "1  /works/OL450063W  Frankenstein or The Modern Prometheus              1818   \n",
       "2   /works/OL18417W             The Wonderful Wizard of Oz              1899   \n",
       "3   /works/OL52267W                       The Time Machine              1895   \n",
       "4  /works/OL262460W                         The Lost World              1900   \n",
       "\n",
       "            author_id  \n",
       "0   /authors/OL22098A  \n",
       "1   /authors/OL25342A  \n",
       "2   /authors/OL23431A  \n",
       "3   /authors/OL13066A  \n",
       "4  /authors/OL161167A  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authors DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11 entries, 0 to 10\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   author_id    11 non-null     object\n",
      " 1   author_name  11 non-null     object\n",
      "dtypes: object(2)\n",
      "memory usage: 308.0+ bytes\n",
      "Books DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13 entries, 0 to 12\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   book_id           13 non-null     object\n",
      " 1   title             13 non-null     object\n",
      " 2   publication_year  13 non-null     int64 \n",
      " 3   author_id         13 non-null     object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 548.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV files into Pandas DataFrames\n",
    "df_authors = pd.read_csv(\"authors.csv\")\n",
    "df_books = pd.read_csv(\"books.csv\")\n",
    "\n",
    "# Display the first few rows to verify correct loading\n",
    "print(\"Authors DataFrame Preview:\")\n",
    "display(df_authors.head())\n",
    "print(\"Books DataFrame Preview:\")\n",
    "display(df_books.head())\n",
    "\n",
    "# Display DataFrame information for a quick structural overview\n",
    "print(\"Authors DataFrame Info:\")\n",
    "df_authors.info()\n",
    "print(\"Books DataFrame Info:\")\n",
    "df_books.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Unique Authors: 11\n"
     ]
    }
   ],
   "source": [
    "### Data Exploration and Summary Statistics\n",
    "\n",
    "# Calculate and print the number of unique authors\n",
    "unique_authors = df_authors[\"author_id\"].nunique()\n",
    "print(f\"Total Unique Authors: {unique_authors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated Metrics - Books per Author per Publication Year:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>num_books</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/authors/OL118077A</td>\n",
       "      <td>1949</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/authors/OL13066A</td>\n",
       "      <td>1895</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/authors/OL13066A</td>\n",
       "      <td>1897</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/authors/OL13066A</td>\n",
       "      <td>1898</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/authors/OL161167A</td>\n",
       "      <td>1900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/authors/OL19767A</td>\n",
       "      <td>1800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/authors/OL20585A</td>\n",
       "      <td>1884</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/authors/OL22098A</td>\n",
       "      <td>1865</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/authors/OL23431A</td>\n",
       "      <td>1899</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/authors/OL25342A</td>\n",
       "      <td>1818</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>/authors/OL3127898A</td>\n",
       "      <td>1800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>/authors/OL31727A</td>\n",
       "      <td>1897</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>/authors/OL44633A</td>\n",
       "      <td>1907</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              author_id  publication_year  num_books\n",
       "0    /authors/OL118077A              1949          1\n",
       "1     /authors/OL13066A              1895          1\n",
       "2     /authors/OL13066A              1897          1\n",
       "3     /authors/OL13066A              1898          1\n",
       "4    /authors/OL161167A              1900          1\n",
       "5     /authors/OL19767A              1800          1\n",
       "6     /authors/OL20585A              1884          1\n",
       "7     /authors/OL22098A              1865          1\n",
       "8     /authors/OL23431A              1899          1\n",
       "9     /authors/OL25342A              1818          1\n",
       "10  /authors/OL3127898A              1800          1\n",
       "11    /authors/OL31727A              1897          1\n",
       "12    /authors/OL44633A              1907          1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated Metrics - Average Books per Author:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>avg_books_per_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/authors/OL118077A</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/authors/OL13066A</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/authors/OL161167A</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/authors/OL19767A</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/authors/OL20585A</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/authors/OL22098A</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/authors/OL23431A</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/authors/OL25342A</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/authors/OL3127898A</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/authors/OL31727A</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>/authors/OL44633A</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              author_id  avg_books_per_year\n",
       "0    /authors/OL118077A                 1.0\n",
       "1     /authors/OL13066A                 1.0\n",
       "2    /authors/OL161167A                 1.0\n",
       "3     /authors/OL19767A                 1.0\n",
       "4     /authors/OL20585A                 1.0\n",
       "5     /authors/OL22098A                 1.0\n",
       "6     /authors/OL23431A                 1.0\n",
       "7     /authors/OL25342A                 1.0\n",
       "8   /authors/OL3127898A                 1.0\n",
       "9     /authors/OL31727A                 1.0\n",
       "10    /authors/OL44633A                 1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute the number of books per author per publication year\n",
    "aggregation = df_books.groupby([\"author_id\", \"publication_year\"]).size().reset_index(name=\"num_books\")\n",
    "\n",
    "# Compute the average number of books per author per year\n",
    "avg_aggregation = aggregation.groupby(\"author_id\")[\"num_books\"].mean().reset_index(name=\"avg_books_per_year\")\n",
    "\n",
    "# Display the aggregated metrics\n",
    "print(\"Aggregated Metrics - Books per Author per Publication Year:\")\n",
    "display(aggregation)\n",
    "print(\"Aggregated Metrics - Average Books per Author:\")\n",
    "display(avg_aggregation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL equivalent\n",
    "### Number of Books Written Each Year by an Author\n",
    "\n",
    "```\n",
    "SELECT\n",
    "    author_name,\n",
    "    year,\n",
    "    COUNT(*) AS num_books\n",
    "FROM books\n",
    "GROUP BY author_name, year\n",
    "ORDER BY author_name, year;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Number of Books Written by an Author per Year\n",
    "```\n",
    "WITH yearly_counts AS (\n",
    "    SELECT\n",
    "        author_name,\n",
    "        year,\n",
    "        COUNT(*) AS num_books\n",
    "    FROM books\n",
    "    GROUP BY author_name, year\n",
    ")\n",
    "SELECT\n",
    "    author_name,\n",
    "    AVG(num_books) AS avg_books_per_year\n",
    "FROM yearly_counts\n",
    "GROUP BY author_name\n",
    "ORDER BY author_name;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimising for a larger dataset\n",
    "\n",
    "\t1.\tIndexing / Partitioning\n",
    "\t•\tIn SQL, create an index on (author_name, year) or partition the table by author_name or year. This speeds up group-by operations and reduces scan times.\n",
    "\t•\tIn Pandas, consider using categorical data for author_name if it has many repeats. This can reduce memory usage.\n",
    "\t2.\tData Warehousing\n",
    "\t•\tFor extremely large data, use a data warehouse or a distributed SQL engine like Amazon Redshift, Google BigQuery, or Apache Hive.\n",
    "\t•\tThese systems are designed to handle massive amounts of data with parallel processing.\n",
    "\t3.\tDistributed Computing (Spark or Dask)\n",
    "\t•\tIf you have to process huge CSV files in Python, libraries like Dask or PySpark can handle out-of-memory datasets by distributing the workload across multiple cores or machines.\n",
    "\t4.\tIncremental Aggregation\n",
    "\t•\tIf your data grows over time, you can incrementally update your aggregates instead of recomputing from scratch. For instance, maintain a table that stores (author_name, year, num_books) and only update the new or changed records."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion \n",
    "\n",
    "The solution was built as a modular data pipeline with distinct components for extraction, transformation, loading, and aggregation. This modular approach allowed us to separate concerns and write targeted unit tests for each component. We used a YAML configuration file to centralize settings (e.g., API endpoints, AWS parameters) so that the system is flexible and easily adjustable. An interactive Jupyter Notebook was created to present the findings, complete with interactive filters, summary dashboards, and visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the current solution is robust for a take-home assessment, a production environment would demand further enhancements:\n",
    "1.\tDatabase Integration:\n",
    "•\tCurrent Approach: We use CSV files as a mock database.\n",
    "•\tProduction Enhancement: I would replace CSV storage with a production-grade relational database (e.g., PostgreSQL on AWS RDS) or even a distributed data warehouse (like Amazon Redshift) to handle large-scale data, support complex queries, and ensure ACID properties. This involves designing a proper schema, indexing key fields (e.g., author_id, publication_year), and implementing ETL pipelines that update the database incrementally.\n",
    "\t\n",
    "\t\n",
    "2.\tScalability and Distributed Processing:\n",
    "•\tCurrent Approach: Data processing is performed using Pandas, which works well on moderate datasets.\n",
    "•\tProduction Enhancement: For larger datasets (millions of records), I’d adopt a distributed processing framework like Apache Spark or Dask. This would allow parallel processing, reduce memory constraints, and improve performance across a cluster of machines.\n",
    "\t\n",
    "3.\tAdvanced Error Handling and Monitoring:\n",
    "•\tCurrent Approach: We log errors and persist error records to a CSV file.\n",
    "•\tProduction Enhancement: Implement comprehensive monitoring and alerting using AWS CloudWatch or Prometheus. This includes real-time metrics for extraction, transformation, and loading phases, as well as alerts for data quality issues. Additionally, integrating automated error review processes would help quickly identify and resolve issues.\n",
    "\n",
    "4.\tContainerization and Orchestration:\n",
    "\t•\tCurrent Approach: The solution is implemented as standalone Python scripts and a Jupyter Notebook.\n",
    "\t•\tProduction Enhancement: I would containerize the pipeline using Docker and orchestrate it with Kubernetes. This ensures consistent deployment, scalability, and easier management across different environments (development, staging, production).\n",
    "\n",
    "5.\tCI/CD and Automated Testing:\n",
    "\t•\tCurrent Approach: The solution includes a GitHub Actions pipeline to run tests and code coverage.\n",
    "\t•\tProduction Enhancement: Extend the CI/CD pipeline to include integration tests in a staging environment, automated deployment to production, and rigorous performance testing. Incorporate static code analysis and security scanning as part of the build process.\n",
    "\n",
    "6.\tData Quality and Governance:\n",
    "\t•\tCurrent Approach: Error records are logged, and basic quality checks are performed.\n",
    "\t•\tProduction Enhancement: Establish a robust data quality framework with automated validations, data profiling, and data lineage tracking. Use tools like Apache Atlas or a data catalog to maintain metadata and ensure data governance.\n",
    "\n",
    "7.\tUser Experience in Reporting:\n",
    "\t•\tCurrent Approach: The interactive notebook provides rich visualizations and interactive filtering.\n",
    "\t•\tProduction Enhancement: Develop a full-fledged dashboard using a BI tool like Tableau or PowerBI, or create a web-based dashboard using frameworks such as Dash or Streamlit. This dashboard would be integrated with real-time data from the production database and provide drill-down capabilities for various business units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Optimising for a larger dataset\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
